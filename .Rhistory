library(jsonlite)
library(httr)
library(dplyr)
setwd("~/Downloads/info201-ab5")
source("api_key.R")
GetData <- function(input.year) {
base.uri <- 'https://api.data.gov/ed/collegescorecard/v1/schools/'
query.params <- list(api_key = api.key, fields = "school.name,school.state,school.city,location.lat,location.lon")
response <- GET(base.uri, query = query.params)
content <- content(response, "text")
body.data <- fromJSON(content) #extract and parse
school.data <- data.frame()
#get total number of pages by dividing total data and num of data per page
all.pages <- trunc(body.data$metadata$total / body.data$metadata$per_page)
#for loop to each page and add that page's data into state.data
for(p in 1:all.pages) {
all.data <- paste0("school.name,school.state,school.city,location.lat,location.lon,",
input.year, ".admissions.admission_rate.overall,",
input.year, ".academics.program.bachelors.library,",
input.year, ".student.share_firstgeneration")
query.params$fields <- paste(all.data)
query.params$page <- p
response <- GET(base.uri, query = query.params)
content <- content(response, "text")
body.data <- fromJSON(content) #extract and parse
page.data <- flatten(body.data$results)
school.data <- rbind(school.data, page.data) #merging the current state data with the current page data
}
return(school.data)
}
school.info <- GetData("2015")
shiny::runApp()
library(shiny)
library(plotly)
library(dplyr)
library(RColorBrewer)
source("./scripts/financial.R")
source("./scripts/ethnicity.R")
source("./scripts/overview_map.R")
library("httr")
library("jsonlite")
library("dplyr")
source('api_key.R')
GetFinData <- function(input.year) {
base.uri <- 'https://api.data.gov/ed/collegescorecard/v1/schools/'
query.params <- list(api_key = api.key, fields = "school.name", school.state = "WA")
response <- GET(base.uri, query = query.params)
content <- content(response, "text")
body.data <- fromJSON(content) #extract and parse
state.data <- data.frame() #empty dataframe
#get total number of pages by dividing total data and num of data per page
total.pages <- trunc(body.data$metadata$total / body.data$metadata$per_page)
#for loop to each page and add that page's data into state.data
for(p in 1:total.pages) {
tuition <- paste0(input.year, ".cost.tuition.in_state,", input.year, ".cost.tuition.out_of_state")
debt <- paste0(input.year, ".aid.median_debt.income.0_30000,",
input.year, ".aid.median_debt.income.30001_75000,",
input.year, ".aid.median_debt.income.greater_than_75000")
query.params$fields <- paste("school.name", tuition, debt, sep=",")
query.params$page <- p
response <- GET(base.uri, query = query.params)
content <- content(response, "text")
body.data <- fromJSON(content) #extract and parse
page.data <- flatten(body.data$results)
state.data <- rbind(state.data, page.data) #merging the current state data with the current page data
}
state.data <- state.data[,c("school.name",
paste0(input.year, ".cost.tuition.in_state"),
paste0(input.year, ".cost.tuition.out_of_state"),
paste0(input.year, ".aid.median_debt.income.0_30000"),
paste0(input.year, ".aid.median_debt.income.30001_75000"),
paste0(input.year, ".aid.median_debt.income.greater_than_75000"))]
names(state.data) <- c("school.name",
"tuition.in",
"tuition.out",
"debt.low",
"debt.med",
"debt.high")
state.data <- state.data %>% mutate(tuition.in = ifelse(is.na(tuition.in), "Not Available", tuition.in))
state.data <- state.data %>% mutate(tuition.out = ifelse(is.na(tuition.out), "Not Available", tuition.out))
state.data <- state.data %>% mutate(debt.low = ifelse(is.na(debt.low), "Not Available", debt.low))
state.data <- state.data %>% mutate(debt.med = ifelse(is.na(debt.med), "Not Available", debt.med))
state.data <- state.data %>% mutate(debt.high = ifelse(is.na(debt.high), "Not Available", debt.high))
names(state.data) <- c("School Name",
"In-State Tuition",
"Out-of-State Tuition",
"Median Debt (Low Income Students)",
"Median Debt (Middle Income Students)",
"Median Debt (High Income Students)")
return(state.data)
}
library(jsonlite)
library(dplyr)
library(httr)
source('api_key.R')
GetRaceData <- function(input.year) {
base.uri <- 'https://api.data.gov/ed/collegescorecard/v1/schools/'
query.params <- list(api_key = api.key, fields = "school.name", school.state = "WA")
response <- GET(base.uri, query = query.params)
content <- content(response, "text")
body.data <- fromJSON(content) #extract and parse
state.data <- data.frame() #empty dataframe
#get total number of pages by dividing total data and num of data per page
total.pages <- trunc(body.data$metadata$total / body.data$metadata$per_page)
#for loop to each page and add that page's data into state.data
for(p in 1:total.pages) {
query.params$fields <- paste0("school.name,",
input.year, ".student.demographics.race_ethnicity.white,",
input.year, ".student.demographics.race_ethnicity.black,",
input.year, ".student.demographics.race_ethnicity.hispanic,",
input.year, ".student.demographics.race_ethnicity.asian,",
input.year, ".student.demographics.race_ethnicity.aian,",
input.year, ".student.demographics.race_ethnicity.nhpi,",
input.year, ".student.demographics.race_ethnicity.two_or_more,",
input.year, ".student.demographics.race_ethnicity.non_resident_alien,",
input.year, ".student.demographics.race_ethnicity.unknown,",
input.year, ".student.demographics.race_ethnicity.white_non_hispanic,",
input.year, ".student.demographics.race_ethnicity.black_non_hispanic,",
input.year, ".student.demographics.race_ethnicity.asian_pacific_islander"
)
query.params$page <- p
response <- GET(base.uri, query = query.params)
content <- content(response, "text")
body.data <- fromJSON(content) #extract and parse
page.data <- flatten(body.data$results)
state.data <- rbind(state.data, page.data) #merging the current state data with the current page data
}
return(state.data)
}
state.data <- GetData(2015)
GetData <- function(input.year) {
base.uri <- 'https://api.data.gov/ed/collegescorecard/v1/schools/'
query.params <- list(api_key = api.key, fields = "school.name,school.state,school.city,location.lat,location.lon")
response <- GET(base.uri, query = query.params)
content <- content(response, "text")
body.data <- fromJSON(content) #extract and parse
school.data <- data.frame()
#get total number of pages by dividing total data and num of data per page
all.pages <- trunc(body.data$metadata$total / body.data$metadata$per_page)
#for loop to each page and add that page's data into state.data
for(p in 1:all.pages) {
all.data <- paste0("school.name,school.state,school.city,location.lat,location.lon,",
input.year, ".admissions.admission_rate.overall,",
input.year, ".academics.program.bachelors.library,",
input.year, ".student.share_firstgeneration")
query.params$fields <- paste(all.data)
query.params$page <- p
response <- GET(base.uri, query = query.params)
content <- content(response, "text")
body.data <- fromJSON(content) #extract and parse
page.data <- flatten(body.data$results)
school.data <- rbind(school.data, page.data) #merging the current state data with the current page data
}
return(school.data)
}
school.info <- GetData("2015")
GetData <- function(input.year) {
base.uri <- 'https://api.data.gov/ed/collegescorecard/v1/schools/'
query.params <- list(api_key = api.key, fields = "school.name,school.state,school.city,location.lat,location.lon")
response <- GET(base.uri, query = query.params)
content <- content(response, "text")
body.data <- fromJSON(content) #extract and parse
school.data <- data.frame()
#get total number of pages by dividing total data and num of data per page
all.pages <- trunc(body.data$metadata$total / body.data$metadata$per_page)
#for loop to each page and add that page's data into state.data
for(p in 1:all.pages) {
all.data <- paste0("school.name,school.state,school.city,location.lat,location.lon,",
input.year, ".admissions.admission_rate.overall,",
input.year, ".student.share_firstgeneration")
query.params$fields <- paste(all.data)
query.params$page <- p
response <- GET(base.uri, query = query.params)
content <- content(response, "text")
body.data <- fromJSON(content) #extract and parse
page.data <- flatten(body.data$results)
school.data <- rbind(school.data, page.data) #merging the current state data with the current page data
}
return(school.data)
}
school.info <- GetData("2015")
runApp()
api.key <- "vt0a8p2WPxbldiZD4QipQNjFsCLAQH2ZA5USPUQd"
GetData <- function(input.year) {
base.uri <- 'https://api.data.gov/ed/collegescorecard/v1/schools/'
query.params <- list(api_key = api.key, fields = "school.name,school.state,school.city,location.lat,location.lon")
response <- GET(base.uri, query = query.params)
content <- content(response, "text")
body.data <- fromJSON(content) #extract and parse
school.data <- data.frame()
#get total number of pages by dividing total data and num of data per page
all.pages <- trunc(body.data$metadata$total / body.data$metadata$per_page)
#for loop to each page and add that page's data into state.data
for(p in 1:all.pages) {
all.data <- paste0("school.name,school.state,school.city,location.lat,location.lon,",
input.year, ".admissions.admission_rate.overall,",
input.year, ".student.share_firstgeneration")
query.params$fields <- paste(all.data)
query.params$page <- p
response <- GET(base.uri, query = query.params)
content <- content(response, "text")
body.data <- fromJSON(content) #extract and parse
page.data <- flatten(body.data$results)
school.data <- rbind(school.data, page.data) #merging the current state data with the current page data
}
return(school.data)
}
school.info <- GetData("2015")
runApp()
runApp('~/Downloads/INFO201/info201-ab5')
runApp('~/Downloads/INFO201/info201-ab5')
runApp('~/Downloads/INFO201/info201-ab5')
jody.key <- "HqfDWgERNoKwmlplx31XyuKy3wW4w8P6BHBHbwe4"
setwd("~/Downloads/INFO201/info201-ab5")
library(jsonlite)
library(httr)
library(dplyr)
source("api_key.R")
jody.key <- "HqfDWgERNoKwmlplx31XyuKy3wW4w8P6BHBHbwe4"
GetData <- function(input.year) {
base.uri <- 'https://api.data.gov/ed/collegescorecard/v1/schools/'
query.params <- list(api_key = api.key, fields = "school.name,school.state,school.city,location.lat,location.lon")
response <- GET(base.uri, query = query.params)
content <- content(response, "text")
body.data <- fromJSON(content) #extract and parse
school.data <- data.frame()
#get total number of pages by dividing total data and num of data per page
all.pages <- trunc(body.data$metadata$total / body.data$metadata$per_page)
#for loop to each page and add that page's data into state.data
for(p in 1:all.pages) {
all.data <- paste0("school.name,school.state,school.city,location.lat,location.lon,",
input.year, ".admissions.admission_rate.overall,",
input.year, ".academics.program.bachelors.library,",
input.year, ".student.share_firstgeneration")
query.params$fields <- paste(all.data)
query.params$page <- p
response <- GET(base.uri, query = query.params)
content <- content(response, "text")
body.data <- fromJSON(content) #extract and parse
page.data <- flatten(body.data$results)
school.data <- rbind(school.data, page.data) #merging the current state data with the current page data
}
return(school.data)
}
school.info <- GetData("2015")
GetData <- function(input.year) {
base.uri <- 'https://api.data.gov/ed/collegescorecard/v1/schools/'
query.params <- list(api_key = jody.key, fields = "school.name,school.state,school.city,location.lat,location.lon")
response <- GET(base.uri, query = query.params)
content <- content(response, "text")
body.data <- fromJSON(content) #extract and parse
school.data <- data.frame()
#get total number of pages by dividing total data and num of data per page
all.pages <- trunc(body.data$metadata$total / body.data$metadata$per_page)
#for loop to each page and add that page's data into state.data
for(p in 1:all.pages) {
all.data <- paste0("school.name,school.state,school.city,location.lat,location.lon,",
input.year, ".admissions.admission_rate.overall,",
input.year, ".academics.program.bachelors.library,",
input.year, ".student.share_firstgeneration")
query.params$fields <- paste(all.data)
query.params$page <- p
response <- GET(base.uri, query = query.params)
content <- content(response, "text")
body.data <- fromJSON(content) #extract and parse
page.data <- flatten(body.data$results)
school.data <- rbind(school.data, page.data) #merging the current state data with the current page data
}
return(school.data)
}
school.info <- GetData("2015")
library(jsonlite)
library(dplyr)
library(httr)
rachel.key <- 'NqLUDcmQG7lM8TniJ3h9ZRmF9bdxp2iKunRVruiN'
GetRaceData <- function(input.year) {
base.uri <- 'https://api.data.gov/ed/collegescorecard/v1/schools/'
query.params <- list(api_key = rachel.key, fields = "school.name", school.state = "WA")
response <- GET(base.uri, query = query.params)
content <- content(response, "text")
body.data <- fromJSON(content) #extract and parse
state.data <- data.frame() #empty dataframe
#get total number of pages by dividing total data and num of data per page
total.pages <- trunc(body.data$metadata$total / body.data$metadata$per_page)
#for loop to each page and add that page's data into state.data
for(p in 1:total.pages) {
query.params$fields <- paste0("school.name,",
input.year, ".student.demographics.race_ethnicity.white,",
input.year, ".student.demographics.race_ethnicity.black,",
input.year, ".student.demographics.race_ethnicity.hispanic,",
input.year, ".student.demographics.race_ethnicity.asian,",
input.year, ".student.demographics.race_ethnicity.aian,",
input.year, ".student.demographics.race_ethnicity.nhpi,",
input.year, ".student.demographics.race_ethnicity.two_or_more,",
input.year, ".student.demographics.race_ethnicity.non_resident_alien,",
input.year, ".student.demographics.race_ethnicity.unknown,",
input.year, ".student.demographics.race_ethnicity.white_non_hispanic,",
input.year, ".student.demographics.race_ethnicity.black_non_hispanic,",
input.year, ".student.demographics.race_ethnicity.asian_pacific_islander"
)
query.params$page <- p
response <- GET(base.uri, query = query.params)
content <- content(response, "text")
body.data <- fromJSON(content) #extract and parse
page.data <- flatten(body.data$results)
state.data <- rbind(state.data, page.data) #merging the current state data with the current page data
}
return(state.data)
}
state.data <- GetRaceData(2015)
sort.state.data <- arrange(state.data, school.name)
View(state.data)
View(state.data)
library("httr")
library("jsonlite")
library("dplyr")
api.key.cece <- "aDmLJNIxppgZ4FYzajfONAUTDllDBE85a1y7fTCR"
GetFinData <- function(input.year) {
base.uri <- 'https://api.data.gov/ed/collegescorecard/v1/schools/'
query.params <- list(api_key = api.key.cece, fields = "school.name", school.state = "WA")
response <- GET(base.uri, query = query.params)
content <- content(response, "text")
body.data <- fromJSON(content) #extract and parse
state.data <- data.frame() #empty dataframe
#get total number of pages by dividing total data and num of data per page
total.pages <- trunc(body.data$metadata$total / body.data$metadata$per_page)
#for loop to each page and add that page's data into state.data
for(p in 1:total.pages) {
tuition <- paste0(input.year, ".cost.tuition.in_state,", input.year, ".cost.tuition.out_of_state")
debt <- paste0(input.year, ".aid.median_debt.income.0_30000,",
input.year, ".aid.median_debt.income.30001_75000,",
input.year, ".aid.median_debt.income.greater_than_75000")
query.params$fields <- paste("school.name", tuition, debt, sep=",")
query.params$page <- p
response <- GET(base.uri, query = query.params)
content <- content(response, "text")
body.data <- fromJSON(content) #extract and parse
page.data <- flatten(body.data$results)
state.data <- rbind(state.data, page.data) #merging the current state data with the current page data
}
state.data <- state.data[,c("school.name",
paste0(input.year, ".cost.tuition.in_state"),
paste0(input.year, ".cost.tuition.out_of_state"),
paste0(input.year, ".aid.median_debt.income.0_30000"),
paste0(input.year, ".aid.median_debt.income.30001_75000"),
paste0(input.year, ".aid.median_debt.income.greater_than_75000"))]
names(state.data) <- c("school.name",
"tuition.in",
"tuition.out",
"debt.low",
"debt.med",
"debt.high")
state.data <- state.data %>% mutate(tuition.in = ifelse(is.na(tuition.in), "Not Available", tuition.in))
state.data <- state.data %>% mutate(tuition.out = ifelse(is.na(tuition.out), "Not Available", tuition.out))
state.data <- state.data %>% mutate(debt.low = ifelse(is.na(debt.low), "Not Available", debt.low))
state.data <- state.data %>% mutate(debt.med = ifelse(is.na(debt.med), "Not Available", debt.med))
state.data <- state.data %>% mutate(debt.high = ifelse(is.na(debt.high), "Not Available", debt.high))
names(state.data) <- c("School Name",
"In-State Tuition",
"Out-of-State Tuition",
"Median Debt (Low Income Students)",
"Median Debt (Middle Income Students)",
"Median Debt (High Income Students)")
return(state.data)
}
View(state.data)
View(sort.state.data)
View(school.info)
fin.data <- GetFinData(2015)
View(fin.data)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
jody.key <- "PEgP9Z9IiZVQwkmTC8j79RpnnaDxSEYz4YqvLhsg"
GetData <- function(input.year) {
base.uri <- 'https://api.data.gov/ed/collegescorecard/v1/schools/'
query.params <- list(api_key = jody.key, fields = "school.name,school.state,school.city,location.lat,location.lon")
response <- GET(base.uri, query = query.params)
content <- content(response, "text")
body.data <- fromJSON(content) #extract and parse
school.data <- data.frame()
#get total number of pages by dividing total data and num of data per page
all.pages <- trunc(body.data$metadata$total / body.data$metadata$per_page)
#for loop to each page and add that page's data into state.data
for(p in 1:all.pages) {
all.data <- paste0("school.name,school.state,school.city,location.lat,location.lon,",
input.year, ".admissions.admission_rate.overall,",
input.year, ".academics.program.bachelors.library,",
input.year, ".student.share_firstgeneration")
query.params$fields <- paste(all.data)
query.params$page <- p
response <- GET(base.uri, query = query.params)
content <- content(response, "text")
body.data <- fromJSON(content) #extract and parse
page.data <- flatten(body.data$results)
school.data <- rbind(school.data, page.data) #merging the current state data with the current page data
}
return(school.data)
}
runApp()
school.info <- GetData("2015")
runApp()
runApp()
runApp()
runApp()
runApp()
runApp('~/Downloads/INFO201/info201-ab5')
runApp('~/Downloads/INFO201/info201-ab5')
GetData <- function(input.year) {
base.uri <- 'https://api.data.gov/ed/collegescorecard/v1/schools/'
query.params <- list(api_key = jody.key, fields = "school.name,school.state,school.city,location.lat,location.lon")
response <- GET(base.uri, query = query.params)
content <- content(response, "text")
body.data <- fromJSON(content) #extract and parse
school.data <- data.frame()
#get total number of pages by dividing total data and num of data per page
all.pages <- trunc(body.data$metadata$total / body.data$metadata$per_page)
#for loop to each page and add that page's data into state.data
for(p in 1:all.pages) {
all.data <- paste0("school.name,school.state,school.city,location.lat,location.lon,",
input.year, ".admissions.admission_rate.overall,",
input.year, ".academics.program.bachelors.library,",
input.year, ".student.share_firstgeneration")
query.params$fields <- paste(all.data)
query.params$page <- p
response <- GET(base.uri, query = query.params)
content <- content(response, "text")
body.data <- fromJSON(content) #extract and parse
page.data <- flatten(body.data$results)
school.data <- rbind(school.data, page.data) #merging the current state data with the current page data
}
return(school.data)
}
school.info <- GetData("2015")
school.info <- school.info %>%
mutate(`2015.student.share_firstgeneration` = `2015.student.share_firstgeneration` * 100,
`2015.admissions.admission_rate.overall` = `2015.admissions.admission_rate.overall` * 100)
View(school.info)
View(school.info)
runApp('~/Downloads/INFO201/info201-ab5')
jody.key <- "PEgP9Z9IiZVQwkmTC8j79RpnnaDxSEYz4YqvLhsg"
runApp('~/Downloads/INFO201/info201-ab5')
library(dplyr)
runApp('~/Downloads/INFO201/info201-ab5')
runApp('~/Downloads/INFO201/info201-ab5')
